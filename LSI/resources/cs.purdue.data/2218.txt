<DOC>
<DOCNO> http://www.cs.purdue.edu/homes/alanqi/Courses/ML-09/lecture-notes.html </DOCNO>
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"> <html> <head> <meta content="text/html; charset=ISO-8859-1" http-equiv="content-type"> <title>lecture-notes</title> </head> <body> &nbsp; You are welcome to download and use these slides. If you use these slides for teaching, your reference to this course website will be appreciated.<br> <br> <table style="text-align: left; width: 1822px; height: 88px;" border="1" cellpadding="2" cellspacing="2"> <tbody> <tr> <td style="vertical-align: top;">Time<br> </td> <td style="vertical-align: top;">&nbsp;Content<br> </td> <td style="vertical-align: top;">Lecture Notes<br> </td> </tr> <tr> <td style="vertical-align: top;">Aug 25<br> </td> <td style="vertical-align: top;">Lecture 1: Course Description and Policy.&nbsp; Introduction to learning from data <br> </td> <td style="vertical-align: top;"><a href="CS59000-ML-1.pdf">PDF slides</a></td> </tr> <tr> <td style="vertical-align: top;">Aug 27<br> </td> <td style="vertical-align: top;">Lecture 2: Curve Fitting, Error Function, Overfitting, Regularization, Bayesian Predictive Distribution, Brief review of&nbsp; probability theory, decision theory, and concepts in information theory (entropy, mutual information and&nbsp; KL divergence) </td> <td style="vertical-align: top;"><a href="CS59000-ML-2.pdf">PDF slides</a><br> </td> </tr> <tr> <td style="vertical-align: top;">Sept 1<br> </td> <td style="vertical-align: top;">Lecture 3: Brief review of&nbsp; probability theory, decision theory, and concepts in information theory (entropy, mutual information and&nbsp; KL divergence) </td> <td style="vertical-align: top;"><a href="CS59000-ML-3.pdf">PDF slide</a><br> </td> </tr> <tr> <td style="vertical-align: top;">Sept 3<br> </td> <td style="vertical-align: top;">Lecture 4: Maximum Likelihood Estimation for Bernoulli and Mulitnomial Distributions, Beta and Dirichilet Distributions, Conjugate Priors, Bayesian Estimation and Predictive Posterior Distributions</td> <td style="vertical-align: top;"><a href="CS59000-ML-4.pdf">PDF slides</a><br> </td> </tr> <tr> <td style="vertical-align: top;">Sept 8<br> </td> <td style="vertical-align: top;">Lecture 5: t-distributions, mixture of Gassuians, Exponential Family,&nbsp; Natural Parameters, Convexity of&nbsp; Normalization Coefficeint, Conjugate Prior for Exponential Family</td> <td style="vertical-align: top;"><a href="CS59000-ML-5.pdf">PDF slides</a><br> </td> </tr> <tr> <td style="vertical-align: top;">Sept 10<br> </td> <td style="vertical-align: top;">Lecture 6: Noinformative Prior, Nonparametric Methods, Parzen Window, K-Nearest-Neigbhors Classification</td> <td style="vertical-align: top;"><a href="CS59000-ML-6.pdf">PDF slides</a><br> </td> </tr> <tr> <td style="vertical-align: top;">Sept 15 <br> </td> <td style="vertical-align: top;">Lecture 7: Linear Regression, Ridge Regression, Lasso, Visualization of Regularized Regression, Bayesian Regression, Model Comparison, Bayes Factor</td> <td style="vertical-align: top;"><a href="CS59000-ML-7.pdf">PDF slides</a></td> </tr> <tr> <td style="vertical-align: top;">Sept 17<br> </td> <td style="vertical-align: top;">Lecture 8:&nbsp; Evidence Framework,&nbsp; Empriical Bayes, Linear Classification Models, Margin, Fishe'sr Linear Discriminant</td> <td style="vertical-align: top;"><a href="CS59000-ML-8.pdf">PDF slides</a></td> </tr> <tr> <td style="vertical-align: top;">Sept 22<br> </td> <td style="vertical-align: top;">Lecture 9: Fishe'sr Linear Discriminant, Perceptron, Generalized Linear Models, Generative Models for classification, Linear Gaussian Classifier</td> <td style="vertical-align: top;"><a href="CS59000-ML-9.pdf">PDF slides</a></td> </tr> <tr> <td style="vertical-align: top;">Sept 24<br> </td> <td style="vertical-align: top;">Lecture 10: Logistiic Regression, Probit Regression, Newton-Raphson Optitimization</td> <td style="vertical-align: top;"><a href="CS59000-ML-10.pdf">PDF slides</a></td> </tr> <tr> <td style="vertical-align: top;">Sept 29<br> </td> <td style="vertical-align: top;">Lecture 11: Laplace Approxmation,&nbsp; BIC model selection,&nbsp; Bayesian Logistic Regression,&nbsp; Kernel Methods, Gram matrix<br> </td> <td style="vertical-align: top;"><a href="CS59000-ML-11.pdf">PDF slides</a></td> </tr> <tr> <td style="vertical-align: top;">Oct 1<br> </td> <td style="vertical-align: top;">Lecture 12: Dual Represenation,&nbsp; Kernel Ridge Regression,&nbsp; Combining Generative and Discriminative Models by Kernels, Fisher&nbsp; Kernel, Kernel PCA</td> <td style="vertical-align: top;"><a href="CS59000-ML-12.pdf">PDF slides</a></td> </tr> <tr> <td style="vertical-align: top;">Oct 6<br> </td> <td style="vertical-align: top;">Lecture 13: Gaussian Processes</td> <td style="vertical-align: top;"><a href="CS59000-ML-13.pdf">PDF slides</a></td> </tr> <tr> <td style="vertical-align: top;">Oct 8<br> </td> <td style="vertical-align: top;">Lecture 14: Gaussian Process Regression, Automatic Relevance Determination</td> <td style="vertical-align: top;"><a href="CS59000-ML-14.pdf">PDF slides</a></td> </tr> <tr> <td style="vertical-align: top;">Oct 16<br> </td> <td style="vertical-align: top;">Lecture 15: Gaussian Process Classification</td> <td style="vertical-align: top;"><a href="CS59000-ML-15.pdf">PDF slides</a></td> </tr> <tr> <td style="vertical-align: top;">Oct 20<br> </td> <td style="vertical-align: top;">Lecture 16: Midterm review<br> </td> <td style="vertical-align: top;"><a href="CS59000-ML-midterm-review.pdf">PDF slides</a></td> </tr> <tr> <td style="vertical-align: top;">Oct 22<br> </td> <td style="vertical-align: top;">Lecture 17: Midterm<br> </td> <td style="vertical-align: top;"><br> </td> </tr> <tr> <td style="vertical-align: top;">Oct 27<br> </td> <td style="vertical-align: top;">Lecture 18: Support Vector Machines for Classification, Introduction to Lagrange Multipliers<br> </td> <td style="vertical-align: top;"><a href="CS59000-ML-18.pdf">PDF slides</a></td> </tr> <tr> <td style="vertical-align: top;">Oct 29<br> </td> <td style="vertical-align: top;">Lecture 19: Support Vector Machines for Classification and Regression,&nbsp; SVM and Regularization, Graphical models, Bayesian networks<br> </td> <td style="vertical-align: top;"><a href="CS59000-ML-19.pdf">PDF slides</a></td> </tr> <tr> <td style="vertical-align: top;">Nov 2<br> </td> <td style="vertical-align: top;">Lecture 20: Conditional Independence,&nbsp; Explaining Away Effect,&nbsp; D-separation,&nbsp; Markvo Chains, Markov Random Fields, ICM, Moralization</td> <td style="vertical-align: top;"><a href="CS59000-ML-20.pdf">PDF slides</a></td> </tr> <tr> <td style="vertical-align: top;">Nov 4<br> </td> <td style="vertical-align: top;">Lecture 21: Inference on chains, Factor graphs, Sum-product algorithm, <br> </td> <td style="vertical-align: top;"><a href="CS59000-ML-21.pdf">PDF slides</a></td> </tr> <tr> <td style="vertical-align: top;">Nov 10<br> </td> <td style="vertical-align: top;">Lecture 22: Sum-product algorithm,&nbsp; Loopy belief propagation, Junction Tree Algorithm, Maximum marginals vs maximum joint distribution, Max-sum algorithm</td> <td style="vertical-align: top;"><a href="CS59000-ML-22.pdf">PDF slides</a></td> </tr> <tr> <td style="vertical-align: top;">Nov 12<br> </td> <td style="vertical-align: top;">Lecture 23: K-means clustering, Vector quantization,, K-medoids clustering, Mixture of Gaussians, Expectation maximization (EM),&nbsp; Lower Bounds in EM</td> <td style="vertical-align: top;"><a href="CS59000-ML-23.pdf">PDF slides</a></td> </tr> <tr> <td style="vertical-align: top;">Nov 17<br> </td> <td style="vertical-align: top;">Lecture 24: Hidden Markvo Models, forward-backward algorithm, EM for learning HMM parameters, Viterbi Algorithm</td> <td style="vertical-align: top;"><a href="CS59000-ML-24.pdf">PDF slides</a></td> </tr> <tr> <td style="vertical-align: top;">Nov 19<br> </td> <td style="vertical-align: top;">Lecture 25: Linear state space models, Kalman filtering and smoothing, Importance Sampling</td> <td style="vertical-align: top;"><a href="CS59000-ML-25.pdf">PDF slides</a></td> </tr> <tr> <td style="vertical-align: top;">Nov 24<br> </td> <td style="vertical-align: top;">Lecture 26: Rejection Sampling, Importance Sampling, Detailed Balance, Metroplis-hasting algorithm, Gibbs sampling</td> <td style="vertical-align: top;"><a href="CS59000-ML-26.pdf">PDF slides</a></td> </tr> </tbody> </table> <br> <br> </body> </html> </html>
</DOC>
