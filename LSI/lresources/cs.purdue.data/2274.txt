<DOC>
<DOCNO> http://www.cs.purdue.edu/homes/ayg/CS525_99/cs525.html </DOCNO>
<html> <head> <title> CS525: Parallel Computing </title> </head> <br> <BODY background="#ffffff"> <h1> CS525: Parallel Computing</h1> <strong> Tu, Th, CS G66 </strong> <br><br> <strong> Ananth Grama<br> 164D, Computer Science Building , 494 6964 <br> <a href="mailto:ayg@cs.purdue.edu"> <i>ayg@cs.purdue.edu</i> </a> <br> <a href="http://www.cs.purdue.edu/people/ayg"> <i> http://www.cs.purdue.edu/people/ayg </i> </a> <br> Office Hours: Wed 1:00 - 3:00 PM. <br> (Office hours can also be arranged by appointment). </strong> <br> <br> <br> <strong> Teaching Assistant: TBA <br> </strong> <hr> <h1> <a href = "grades_525_99.html"> Grades</a> </h1> <strong> These grades have been computed based on 40% for 4 homeworks, 10% for the project, 20% for the midterm, and 30% for the final. <br> <br> Colombo Clause: (Restated without permission of accomplished UI Law Educator John Colombo) <br> </strong> If you want to discuss your exam, you will need to make an appointment with me (e-mail is best to arrange this). At this point, the final exam and project grades are the only grades open to discussion. Please do not come to me for regrades on your homeworks or midterms. If you are coming in to argue about the two points you need to get you from a B to an A, please save your breath. While I sympathize with those who fall just under the cutoffs, it is the nature of the system we work in. There will always be someone just under the cutoff. I gave grading the best shot I could give it. <br> <br> <hr> <hr> CS525, Parallel Computing deals with emerging trends in the use of large scale computing platforms ranging from tightly coupled SMPs and message passing parallel computers to loosely connected clusters and multiclusters. The course consists of four major parts: <ul> <li> Parallel computing platforms: This part of the class outlines parallel computing hardware. Topics covered include processor and memory architectures, SMP and message passing hardware, interconnection networks, network hardware, and evaluation metrics for architectures. Cost models for communication are also developed. <li> Parallel Algorithms: Starting from design principles for parallel algorithms, this part develops parallel algorithms for a variety of problems. Various metrics for evaluating these algorithms are also discussed. <li> Parallel Programming: Programming models and language support for programming parallel platforms is discussed in this part. Message passing using MPI, thread-based programming using POSIX threads, and directive-based programming using OpenMP will be discussed. In addition, CORBA, Java RMI, NI, and threads will also be covered. System software issues relating to threads and distributed object systems will be studied. <li> Applications: A variety of parallel applications from diverse domains such as data analysis, graphics and visualization, particle dynamics, and discrete event and direct numerical simulations will be discussed. </ul> <h2> Remember: Midterm on Thursday, Apr 8, 1999 </h2> <h3> Grading Policies: </h3> The grade for this class will be determined by performance on midterms, finals and homeworks/projects. The precise breakup of grades will be announced soon. <h3> <a href = "projects.html">List of Projects</a> </h3> <h3> Assignments: </h3> <a href = "assignments/assn1.ps"> Assignment 1, Due Feb 16 1999</a> <br> <a href = "assignments/assn2.ps"> Assignment 2, Due Mar 04 1999</a> <br> <a href = "assignments/assn3.ps"> Assignment 3, Due Mar 23 1999</a> <br> <a href = "assignments/assn4.ps"> Assignment 4, Due Apr 15 1999</a> <br> <br> <br> Study Material: <br> <a href = "../CS590V/tests/mt1.ps"> Midterm 1, 1997</a><br> <a href = "mt2_97.ps"> Midterm 2, 1997</a><br> <a href = "final_97.ps"> Final, 1997</a><br> <a href = "mt1_98.ps"> Midterm 1l, 1998</a><br> <a href = "final_98.ps"> Final, 1998</a><br> <h3> Notes and Study Material: </h3> In addition to handouts and other online material, the course will use the following texts: <br> <br> <ul> <li> <a href = "http://www.mcs.anl.gov/dbpp/text/node1.html"> Designing and Building Parallel Programs by Ian Foster, Addison Wesley Inc. </a> <br> <br> <li> <a href = "material.html"> Introduction to Parallel Programming (Pre-Publication Notes) by Vipin Kumar, Ananth Grama, and George Karypis </a> <br> <br> <li> <a href = "ftp://ftp.cs.umn.edu/users/kumar/book/"> Introduction to Parallel Computing: Design and Analysis of Algorithms by Vipin Kumar, Ananth Grama, Anshul Gupta and George Karypis, Benjamin Cummings / Addison Wesley, 1994. </a> </ul> <h3> Other Useful Links: </h3> <ul> <li> <a href="http://quest.cc.purdue.edu/SP2/"> Getting Started on Purdue's SP2</a> <li> <a href = "http://computer.org/ParaScope/"> Whole bunch of parallel computing links</a> <li> <a href = "http://www.partner.digital.com/www-swdev/pages/Home/TECH/documents/Digital_UNIX/V4.0/AA-Q2DPC-TKT1_html/thrd.html"> A Guide to POSIX Threads</a> <li> <a href = "http://www.openmp.org/"> OpenMP: A standard for Directive Based Parallel Programming</a> <li> <a href = "http://www.mpi-forum.org/"> The MPI (Message Passing Interface) Forum </a> <li> <a href = "http://java.sun.com/products/jdk/1.1/docs/guide/rmi/getstart.doc.html"> Guide to Java RMI</a> <li> <a href = "http://www.omg.org/corba/beginners.html> CORBA Beginners Guide</a> Guide</a>
</DOC>
